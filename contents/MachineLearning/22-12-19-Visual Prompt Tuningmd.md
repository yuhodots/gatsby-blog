---
title: "Visual Prompt Tuning"
date: "2022-12-19"
template: "post"
draft: true
path: "/deeplearning/22-12-19/"
description: "ECCV 2022에서 발표된 Visual Prompt Tuning 논문을 간단히 정리합니다. 본 논문은 Large-scale vision Transformer model을 fine-tuning 할 때, 전체 모델의 1% 이하의 파라미터만 튜닝하면서도 좋은 성능을 낼 수 있는 Visual Prompt Tuning 방법을 제안합니다."
category: "Deep Learning"
thumbnail: "deeplearning"
---

> ECCV 2022에서 발표된 Visual Prompt Tuning 논문을 간단히 정리합니다. 본 논문은 Large-scale vision Transformer model을 downstream task에 대해 fine-tuning 할 때, 전체 모델의 1% 이하의 파라미터만 튜닝하면서도 전체 파라미터를 튜닝하는 방법 만큼의 성능을 낼 수 있는 Visual Prompt Tuning 방법을 제안합니다.

### Introduction



##### Prior Work

- 

##### Prompting

- NLP에서의 prompt tuning

### Visual Prompt Tuning



##### VPT-Deep



##### VPT-Shallow



### Experiments



### Conclusion



### References

[^1]:Menglin Jia, et al., "Visual prompt tuning," ECCV 2022.
