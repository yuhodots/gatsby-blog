{"componentChunkName":"component---src-templates-post-js","path":"/deeplearning/24-07-11/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p>NeurIPS 2022에서 발표된 Matryoshka Representation Learning 논문을 정리합니다.</p>\n</blockquote>\n<p>이미지나 텍스트의 embedding을 뽑고자 할 때 여러 pre-trained backbone을 활용하는 경우가 많은데, 이 때 필요에 따라 특정 dimension으로 embedding을 맞춰줘야 하는 경우가 꽤나 빈번하게 발생합니다. 단순히 일부 값만 뽑아 사용하기에는 어떤 dimension number가 유용한지 판단할 수 없고, 따라서 PCA와 같은 linear projection 방법을 사용하거나 projection layer를 붙여 fine-tuning을 하곤 합니다. 하지만 이러한 방식은 기존 성능이 충분히 유지되지 않거나 추가 학습이 필요하다는 단점이 있습니다. 그래서 '배포 시점에서 필요한 feature dimension을 바로 선택해서 사용할 순 없을까'하는 고민이 개인적으로 항상 있었습니다. </p>\n<p>그러다 최근에 NomicAI의 nomic-embed-text-v1.5를 사용할 일이 있었는데, 해당 embedding은 단순 slicing으로 원하는 embedding dimension을 선정하더라도 성능이 유지된다고 주장하고 있었습니다. 여기에 적용된 방법이 Matryoshka Representation Learning이라는 것을 확인하여 해당 논문을 읽게 되었고, 관련 내용을 아래에 정리하여 공유합니다.</p>\n<h3 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h3>\n<p>들어가기에 앞서 논문에서 소개하는 key contribution은 다음과 같습니다. </p>\n<ul>\n<li>Adaptive deployment을 위한 flexible representation을 얻을 수 있음</li>\n<li>Large-scale classification과 retrieval 분야에서 14배까지 빠르면서도 기존 baseline 성능을 유지 할 수 있음</li>\n<li>해당 방법은 vision, language, VLM 등 여러 modality로도 매끄럽게 adpatation이 가능함</li>\n</ul>\n<p>해당 논문을 적용 가능한 대표적인 분야는 classification과 retrieval 분야인데, 특히 retrieval 분야는 web scale 데이터에서도 embedding search를 빠르게, 효율적으로, 그리고 정확하게 수행할 수 있는 능력이 중요합니다. 이 때 대부분 이슈가 되는 영역이 label 수(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi></mrow><annotation encoding=\"application/x-tex\">L</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">L</span></span></span></span>), 데이터 양(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span>), 그리고 embedding size(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span>) 입니다. </p>\n<p>Label 수와 관련되어 보편적으로 사용되고 있는 방법은 Approximate Nearest Neighbor Search(ANNS)이나 Hierarchical Navigable Small World(HNSW) 같은 hierarchy 기반의 방법들이고, 특히 이 중 HNSW는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>d</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(dlog(N))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span> 방법이지만 성능은 exact retrieval <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mi>d</mi><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(O(dN)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span>만큼이나 좋다는 장점을 가지고 있습니다 (HNSW에 대한 간단한 설명을 <a href=\"https://yuhodots.github.io/Operations/23-11-19/\">이전 글</a>에서 확인 가능합니다).</p>\n<p>본 논문에서 제안하는 Matryoshka Representation Learning(이하 MRL)은 embedding size <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span>에 집중하고, high dimension vector와 search 방법론들 사이에 좋은 intermediate abstraction을 제공함으로써 ANNS과 같은 retrieval을 더욱 효율적으로 할 수 있도록 돕습니다. </p>\n<h3 id=\"matryoshka-representation-learning\" style=\"position:relative;\"><a href=\"#matryoshka-representation-learning\" aria-label=\"matryoshka representation learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Matryoshka Representation Learning</h3>\n<center><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/c5e63e22bf322057ab211e4bbef7852d/aea0a/2024-07-11-0.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 48.94736842105264%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAABrElEQVQoz32S607bQBCF/fCV+gxIFZAW1IqLaItUVeIHFFRQBMHpxV7HiWyv49hEjW9x4rUdnNOJ41BApCN9mtHsOavdnZXm8zmex6o3mUxh2zYcx6kwLQtBEDzRPPdJeCFW0jRNYRgGGGPQNI1g8H2/NuPFkO6zGLH2HhHbIXarHFMO1R0MWptw5QaxTfUWvHaj6vm/35Jnt/Ys9ZGyjTwyIJVFgqR3hLG+Txw8od96B6u5BePqDfSLDZhU8+sGQraHRD98pKVa+4BizCHNZveIkwTc68HyuuB3y7zAHvYw8B1YQwuccEMX/aFB2uU6r/Wm28Hgj42SnkEqyxLFrEBWpMjyaZ1XdYbYbcJVP8JRPsE3TiDSgPrin7b25dRbO5THkVtfwM9eQ/n6Cr68QdMQa7XVhkVeIB5HdGwGw1FgDtQq6/YPdHgbXVuG0r2Ebt7A9hitM1iu9gD3OqRXMQq95ZSFEHDv+vjW+ozT6yOcy8c4vz3Gr24TmimDEap5i2A8gsgFpiJ5IF2QTao6p+epNsyyHEE4QrvzHT/1K/jRkIYUrv1n/4vFlf8CStDoPzf5jH0AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <picture>\n          <source srcset=\"/static/c5e63e22bf322057ab211e4bbef7852d/15813/2024-07-11-0.webp 190w,\n/static/c5e63e22bf322057ab211e4bbef7852d/1cdb2/2024-07-11-0.webp 380w,\n/static/c5e63e22bf322057ab211e4bbef7852d/9046c/2024-07-11-0.webp 760w,\n/static/c5e63e22bf322057ab211e4bbef7852d/c89f9/2024-07-11-0.webp 1140w,\n/static/c5e63e22bf322057ab211e4bbef7852d/7afe4/2024-07-11-0.webp 1520w,\n/static/c5e63e22bf322057ab211e4bbef7852d/a466f/2024-07-11-0.webp 2018w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/webp\">\n          <source srcset=\"/static/c5e63e22bf322057ab211e4bbef7852d/a2d4f/2024-07-11-0.png 190w,\n/static/c5e63e22bf322057ab211e4bbef7852d/3f520/2024-07-11-0.png 380w,\n/static/c5e63e22bf322057ab211e4bbef7852d/3c051/2024-07-11-0.png 760w,\n/static/c5e63e22bf322057ab211e4bbef7852d/b5cea/2024-07-11-0.png 1140w,\n/static/c5e63e22bf322057ab211e4bbef7852d/891d5/2024-07-11-0.png 1520w,\n/static/c5e63e22bf322057ab211e4bbef7852d/aea0a/2024-07-11-0.png 2018w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/png\">\n          <img class=\"gatsby-resp-image-image\" src=\"/static/c5e63e22bf322057ab211e4bbef7852d/3c051/2024-07-11-0.png\" alt=\"2024 07 11 0\" title=\"2024 07 11 0\" loading=\"lazy\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\">\n        </picture>\n  </a>\n    </span><p><i>Taken from, https://huggingface.co/blog/matryoshka</i></p></center>\n<p>위의 figure는 MRL의 장점을 직관적으로 표현하고 있습니다. 그리고 아래의 figure를 통해서는 MRL의 학습 방식을 직관적으로 확인하실 수 있습니다. </p>\n<center><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/80ee4a8d5e58115696f454fa7e15299e/84ee5/2024-07-11-1.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 36.84210526315789%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABKUlEQVQoz42RTU/CQBCG+ZX+Jc9GTUy8G0OIAS8S9GI4VCMRtbSoCALBQqEWSrdbaCuPpYrhIxon2czu7Myz8+6kWLLZbJZ4xxmhaxXMXvc7DoOBydh147sx1WqVIAhWahaWWocJ10bXNRSlxG1ZxWw/QTQhu79DR1OZegLbHuL7/krdwi8BPxL/brUoKIekC7vkLveo1YpJPHu0Tauu4cspQogf4HqXGx1Kb4im51FuTijf57CtGvOnOsUtpKUQxQcpPSzLSta69A2gL8d49jPmS5lRV0WM3pL4+VmaQd9I9mEYxrJtPM8jiqK/gcIxMB5PuSocUK9kMJrX8SAEx+kMPbOf5MwhUsr/SQ4mHu3GA+3XO5oNFdf5gpQu8lhdgzCGzf/vt6F8AkwyE8zUPZVDAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <picture>\n          <source srcset=\"/static/80ee4a8d5e58115696f454fa7e15299e/15813/2024-07-11-1.webp 190w,\n/static/80ee4a8d5e58115696f454fa7e15299e/1cdb2/2024-07-11-1.webp 380w,\n/static/80ee4a8d5e58115696f454fa7e15299e/9046c/2024-07-11-1.webp 760w,\n/static/80ee4a8d5e58115696f454fa7e15299e/ceabe/2024-07-11-1.webp 1076w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/webp\">\n          <source srcset=\"/static/80ee4a8d5e58115696f454fa7e15299e/a2d4f/2024-07-11-1.png 190w,\n/static/80ee4a8d5e58115696f454fa7e15299e/3f520/2024-07-11-1.png 380w,\n/static/80ee4a8d5e58115696f454fa7e15299e/3c051/2024-07-11-1.png 760w,\n/static/80ee4a8d5e58115696f454fa7e15299e/84ee5/2024-07-11-1.png 1076w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/png\">\n          <img class=\"gatsby-resp-image-image\" src=\"/static/80ee4a8d5e58115696f454fa7e15299e/3c051/2024-07-11-1.png\" alt=\"2024 07 11 1\" title=\"2024 07 11 1\" loading=\"lazy\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\">\n        </picture>\n  </a>\n    </span><p><i>Taken from, Aditya Kusupati, et al.</i></p></center>\n<p>MRL은 각 데이터 포인트 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>에 대한 embedding vector <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi></mrow><annotation encoding=\"application/x-tex\">z</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span></span>의 처음 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span> 차원 각각을 독립적으로 작동할 수 있게 합니다. 각 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span> 차원을 {8, 16, . . . , 1024, 2048}으로 선택했다고 했을 때, 각 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span> dimension 마다 독립적인 linear classifier <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"bold\">W</mi><mi>m</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\mathbf W_m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83611em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01597em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>만들고, 각 linear classifier의 output에 대한 loss를 계산하고 aggregate(weighted sum)합니다. 결론적으로는 아래 식을 통해 MRL이 학습되며, 실험에서 weight <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>c</mi><mi>m</mi></msub></mrow><annotation encoding=\"application/x-tex\">c_m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>은 모든 dimension에 대해 1로 고정합니다.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><munder><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mo stretchy=\"false\">{</mo><mi mathvariant=\"bold\">W</mi><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo><msub><mo stretchy=\"false\">}</mo><mrow><mi>m</mi><mo>∈</mo><mi mathvariant=\"script\">M</mi></mrow></msub><mo separator=\"true\">,</mo><msub><mi>θ</mi><mi>F</mi></msub></mrow></munder><mfrac><mn>1</mn><mi>N</mi></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mi>N</mi><mo stretchy=\"false\">]</mo></mrow></munder><munder><mo>∑</mo><mrow><mi>m</mi><mo>∈</mo><mi mathvariant=\"script\">M</mi></mrow></munder><msub><mi>c</mi><mi>m</mi></msub><mo>⋅</mo><mi mathvariant=\"script\">L</mi><mrow><mo fence=\"true\">(</mo><msup><mi mathvariant=\"bold\">W</mi><mrow><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>⋅</mo><mi>F</mi><msub><mrow><mo fence=\"true\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">;</mo><msub><mi>θ</mi><mi>F</mi></msub><mo fence=\"true\">)</mo></mrow><mrow><mn>1</mn><mo>:</mo><mi>m</mi></mrow></msub><mo separator=\"true\">;</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\min _{\\{\\mathbf{W}(m)\\}_{m \\in \\mathcal{M}}, \\theta_F} \\frac{1}{N} \\sum_{i \\in[N]} \\sum_{m \\in \\mathcal{M}} c_m \\cdot \\mathcal{L}\\left(\\mathbf{W}^{(m)} \\cdot F\\left(x_i ; \\theta_F\\right)_{1: m} ; y_i\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.8374449999999998em;vertical-align:-1.516005em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.66786em;\"><span style=\"top:-2.3089999999999997em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">{</span><span class=\"mord mtight\"><span class=\"mord mathbf mtight\" style=\"margin-right:0.01597em;\">W</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">m</span><span class=\"mclose mtight\">)</span><span class=\"mclose mtight\"><span class=\"mclose mtight\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3567071428571427em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mrel mtight\">∈</span><span class=\"mord mtight\"><span class=\"mord mathcal mtight\">M</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1712214285714286em;\"><span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3567071428571427em;margin-left:-0.02778em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">F</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14329285714285717em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span><span class=\"mop\">min</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.966em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.050005em;\"><span style=\"top:-1.808995em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">∈</span><span class=\"mopen mtight\">[</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose mtight\">]</span></span></span></span><span style=\"top:-3.0500049999999996em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.516005em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.050005em;\"><span style=\"top:-1.8556639999999998em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mrel mtight\">∈</span><span class=\"mord mtight\"><span class=\"mord mathcal mtight\">M</span></span></span></span></span><span style=\"top:-3.0500049999999996em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.321706em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.80002em;vertical-align:-0.65002em;\"></span><span class=\"mord\"><span class=\"mord mathcal\">L</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">W</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">m</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">F</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151408em;\"><span style=\"top:-2.4003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">m</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29969999999999997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></span>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">W</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">W</span></span></span></span>를 dimension 별로 여럿 두는 것이 아니라 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>W</mi><mi>m</mi></msub><mo>=</mo><msub><mi>W</mi><mrow><mn>1</mn><mo>:</mo><mi>m</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">W_m = W_{1:m}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">m</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 형태로 하나의 weight만 두고 slicing하는 weight-tying 방식을 선택할 수도 있습니다. 이 방식은 linear classifier의 weight 수가 절반으로 줄기 때문에 memory cost를 줄일 수 있고 extremely large output space일때 효과적입니다. 해당 방식을 논문에서는 MRL-E(Efficient Matryoshka Representation Learning)로 명명하고 있습니다. </p>\n<h3 id=\"applications\" style=\"position:relative;\"><a href=\"#applications\" aria-label=\"applications permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Applications</h3>\n<center><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/11fb944afd15213e986fc33c4fec6aed/71dc1/2024-07-11-2.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 48.42105263157895%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB10lEQVQoz11SCc+iMBDl//81jUYNKqsfHx5AW3oA5RAV3850j2y2STNA37xjSjSOI9qmQd16aGtQWUvVQlUKpdQolcbn88Hr9Qo47zto5wLWOEvbQBveNuAiSy+5Ujhdz8hEga/ijni3wWYbIzldcMslhmFAU9eQxuEsC2T5Ben5hCRLsd4fcEwyXO8K82dGpCqN7/s3pqEGr4nUfSUh2WFRYiQy7z2ElPhxSdB1hCOXTxbRFYoihyglOvo2z0QoRInBCrzfb0zPJxpyPI4US1xDjL7v0bYtlBLovcX8mDCNA5w28K6GkTdYMtF1XeCIDBGwA14Pqr3RmN8fdNajKAsiUoHU0lw7mvNMzobOo7UtXtObSFvk5FJSgjBDnk8gJQWrJBpSc9ZBCYE8zylSEaIMdHlGa7R0bqk6W8PRpSgiYlxZlr8I2dmToj4eD5hwu1U4rLiZojZ0s38W4/iv4FtVJM5i+j9c5H7n58oAVhPkjqMyiBMwCaeYpik03263IMoxKzLA/YwJM9ztdkiSBMvlEvzMe7vdYr/fY71eI47jILJYLJCm6d+zw+EQ+rhuNpvwjQUjbmKy1WqFLMtCBHbLyvxc0//Hzpno381CXJmMe4/HY5j1Txxi7STZUlt2AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <picture>\n          <source srcset=\"/static/11fb944afd15213e986fc33c4fec6aed/15813/2024-07-11-2.webp 190w,\n/static/11fb944afd15213e986fc33c4fec6aed/1cdb2/2024-07-11-2.webp 380w,\n/static/11fb944afd15213e986fc33c4fec6aed/9046c/2024-07-11-2.webp 760w,\n/static/11fb944afd15213e986fc33c4fec6aed/c89f9/2024-07-11-2.webp 1140w,\n/static/11fb944afd15213e986fc33c4fec6aed/7afe4/2024-07-11-2.webp 1520w,\n/static/11fb944afd15213e986fc33c4fec6aed/f4e8b/2024-07-11-2.webp 2346w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/webp\">\n          <source srcset=\"/static/11fb944afd15213e986fc33c4fec6aed/a2d4f/2024-07-11-2.png 190w,\n/static/11fb944afd15213e986fc33c4fec6aed/3f520/2024-07-11-2.png 380w,\n/static/11fb944afd15213e986fc33c4fec6aed/3c051/2024-07-11-2.png 760w,\n/static/11fb944afd15213e986fc33c4fec6aed/b5cea/2024-07-11-2.png 1140w,\n/static/11fb944afd15213e986fc33c4fec6aed/891d5/2024-07-11-2.png 1520w,\n/static/11fb944afd15213e986fc33c4fec6aed/71dc1/2024-07-11-2.png 2346w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/png\">\n          <img class=\"gatsby-resp-image-image\" src=\"/static/11fb944afd15213e986fc33c4fec6aed/3c051/2024-07-11-2.png\" alt=\"2024 07 11 2\" title=\"2024 07 11 2\" loading=\"lazy\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\">\n        </picture>\n  </a>\n    </span><p><i>Taken from, Aditya Kusupati, et al.</i></p></center>\n<p>실험에서는 하이퍼파라미터 서치를 따로 하지 않고 baseline 실험들의 하이퍼파라미터를 그대로 사용하였습니다. ImageNet 1K에 대해 linear classification 성능과 1-NN 성능을 측정하였는데, 첫번째 실험에서는 FF(Fixed feature) model (i.e., convetional trained model)과 MRL의 성능이 모든 representation size에서 동일하였고, 두번째 실험에서는 MRL가 lower dimension에서 강점을 갖는다는 것을 확인하였습니다. FF model과 성능이 비슷하지만 MRL는 배포 시점에서 자유롭게 dimension을 골라서 사용할 수 있으니 효과적이라고 볼 수 있습니다.</p>\n<center><span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 760px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/d60e075424841f95f52f624e0c09a01e/2a50e/2024-07-11-3.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 47.89473684210526%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB0UlEQVQoz01R27KiMBDk/z9sX3zxjrp61IOCQAKJIYgg9k7Hsmqpmpow6el0z0TONdBFBaMMjDZQRY1aWdjKfbJ14DcMA5y7S3gUWqOsNapa8KpCUVa45QrP5xORlstn10PZBkchKyXfyhJJ8gtjNFytML7fqKpKCCx2aYI4+cHuGOOwm+FvPMNm+gfn/RZt+0B0u91gfAfXDVJwGPoHnNUwVY6u8/DeoZOXszTD4XKCMhnwGvEWZ42zuGS/OBwPcI3guk4IixK2acVTh3HoQwwS1rWwxuDuHB6PB46nM2p9EViLTqzSnlE5THGFKpWIaQMuKooC4+v1IRvfwV7f99KsUIp1I6TjOAbLTeMx9gMGafQyTy/jaY1HmqUgTyB0osBYG5RYyfzXMmiVl8iyDHmeh6V47wOpreugvJIHtSyjLHKkaYrr9fpZyhfMZs7zm1PJXBi3+/145pxIXIh64qiMImp5iE4iXtL//X4PQF4qpfCtUzUzrdMS76nmGxRAMoriqKLpdIrtdos4jsHzer3GfD4P+Xw+YzabBRX/45bLJTabDVarVTizzns+GrFhMpkEktPphP1+H8gIZCYBFbNhsVgEEtaIZ41BbJIkYST/AGjE7oGrWS0iAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <picture>\n          <source srcset=\"/static/d60e075424841f95f52f624e0c09a01e/15813/2024-07-11-3.webp 190w,\n/static/d60e075424841f95f52f624e0c09a01e/1cdb2/2024-07-11-3.webp 380w,\n/static/d60e075424841f95f52f624e0c09a01e/9046c/2024-07-11-3.webp 760w,\n/static/d60e075424841f95f52f624e0c09a01e/c89f9/2024-07-11-3.webp 1140w,\n/static/d60e075424841f95f52f624e0c09a01e/7afe4/2024-07-11-3.webp 1520w,\n/static/d60e075424841f95f52f624e0c09a01e/f3c66/2024-07-11-3.webp 2352w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/webp\">\n          <source srcset=\"/static/d60e075424841f95f52f624e0c09a01e/a2d4f/2024-07-11-3.png 190w,\n/static/d60e075424841f95f52f624e0c09a01e/3f520/2024-07-11-3.png 380w,\n/static/d60e075424841f95f52f624e0c09a01e/3c051/2024-07-11-3.png 760w,\n/static/d60e075424841f95f52f624e0c09a01e/b5cea/2024-07-11-3.png 1140w,\n/static/d60e075424841f95f52f624e0c09a01e/891d5/2024-07-11-3.png 1520w,\n/static/d60e075424841f95f52f624e0c09a01e/2a50e/2024-07-11-3.png 2352w\" sizes=\"(max-width: 760px) 100vw, 760px\" type=\"image/png\">\n          <img class=\"gatsby-resp-image-image\" src=\"/static/d60e075424841f95f52f624e0c09a01e/3c051/2024-07-11-3.png\" alt=\"2024 07 11 3\" title=\"2024 07 11 3\" loading=\"lazy\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\">\n        </picture>\n  </a>\n    </span><p><i>Taken from, Aditya Kusupati, et al.</i></p></center>\n<p>Adaptive classification task를 위해서는 dimension 별로 maximum softmax probability에 대한 threshold를 validation set에 대해 학습하고, 이를 MRL의 representation의 dimension을 결정하는데에 사용합니다. Baseline과 동일한 수준의 accuracy를 14배 작은 모델 만으로도 달성할 수 있었습니다. ImageNet 1K에 대한 retrieval task에서는 Basleline 보다 3%정도 성능 향상이 있었고 특히 256 dimension 아래에서 더 유용했습니다. </p>\n<h5 id=\"further-analysis\" style=\"position:relative;\"><a href=\"#further-analysis\" aria-label=\"further analysis permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Further Analysis</h5>\n<p>Robustness를 측정하기 위해 저자들은 ImageNet 1K 말고 다른 데이터셋에 대한 실험도 진행하였으며, ImageNet-A에 대해서는 baseline 만큼 성능이 보장되었고, ImageNet 1K를 쿼리로하여 ImageNet V2에 대한 retrieval을 했을 때는 basline 보다 mAP@10에서 3%정도의 향상이 있었습니다. </p>\n<p>Few-shot &#x26; Long-tail 데이터 셋에 대해서도 실험을 진행하였는데 기존 base classes에 대한 성능을 유지하면 novel classes에 대해 2%정도의 성능 향상이 있었다고 합니다.</p>\n<h3 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h3>\n<p>제 경우에는 CLIP에서 text encoder 파트를 nomic text embedding v1.5 512 dimension으로 대체하기 위해 해당 방식을 사용하였는데, 이런 경우 뿐만 아니라 RAG와 같은 embedding search에서도 상당히 유용하게 써볼 수 있겠다는 생각이 들었습니다.</p>\n<p>서비스에서 원하는 dimension을 adaptation이나 추가 튜닝 없이 slicing하여 사용한다는 것이 생각보다 큰 강점이라서, 실서비스 단에서 활용하기에 꽤 좋은 방식이라는 생각이 들었습니다. </p>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<p>Kusupati, Aditya, et al. \"Matryoshka representation learning.\" <em>Advances in Neural Information Processing Systems</em> 35 (2022): 30233-30249.</p>","tableOfContents":"<ul>\n<li><a href=\"/MachineLearning/24-07-11-Matryoshka%20Representation%20Learning/#introduction\">Introduction</a></li>\n<li><a href=\"/MachineLearning/24-07-11-Matryoshka%20Representation%20Learning/#matryoshka-representation-learning\">Matryoshka Representation Learning</a></li>\n<li>\n<p><a href=\"/MachineLearning/24-07-11-Matryoshka%20Representation%20Learning/#applications\">Applications</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"/MachineLearning/24-07-11-Matryoshka%20Representation%20Learning/#further-analysis\">Further Analysis</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"/MachineLearning/24-07-11-Matryoshka%20Representation%20Learning/#conclusion\">Conclusion</a></li>\n<li><a href=\"/MachineLearning/24-07-11-Matryoshka%20Representation%20Learning/#reference\">Reference</a></li>\n</ul>","frontmatter":{"path":"/deeplearning/24-07-11/","title":"Matryoshka Representation Learning","category":"Deep Learning","date":"2024-07-11"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}