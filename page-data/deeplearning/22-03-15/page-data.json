{"componentChunkName":"component---src-templates-post-js","path":"/deeplearning/22-03-15/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p>관심 분야의 논문 리스트를 기록합니다. 최근에 읽은 논문은 핵심 내용을 세 줄 요약으로 추가하고 있습니다. 체크 표시가 되어있지 않은 논문들은 추후 다시 읽어 볼 필요가 있는 논문을 의미합니다.</p>\n</blockquote>\n<h3 id=\"few-shot-learning-meta-learning\" style=\"position:relative;\"><a href=\"#few-shot-learning-meta-learning\" aria-label=\"few shot learning meta learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Few-shot Learning, Meta Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3157382.3157504\">Vinyals, Oriol, et al. \"Matching networks for one shot learning.\" NIPS 2016.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://proceedings.mlr.press/v48/santoro16.pdf\">Santoro, et al. \"Meta-Learning with Memory-Augmented Neural Networks.\" ICML 2016.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3294996.3295163\">Snell, Jake, Kevin Swersky, and Richard Zemel. \"Prototypical networks for few-shot learning.\" NIPS 2017.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v97/yoon19a.html\">Yoon, Sung Whan, Jun Seo, and Jaekyun Moon. \"TapNet: Neural network augmented with task-adaptive projection for few-shot learning.\" ICML 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v70/finn17a\">Finn, Chelsea, Pieter Abbeel, and Sergey Levine. \"Model-agnostic meta-learning for fast adaptation of deep networks.\" ICML 2017.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2006.08306\">Mukaiyama, Kei, Issei Sato, and Masashi Sugiyama. \"LFD-Protonet: prototypical network based on local fisher discriminant analysis for few-shot learning.\" arXiv preprint arXiv:2006.08306, 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1805.10002\">Liu, Yanbin, et al. \"Learning to propagate labels: Transductive propagation network for few-shot learning.\" ICLR 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Edge-Labeling_Graph_Neural_Network_for_Few-Shot_Learning_CVPR_2019_paper.html\">Kim, Jongmin, et al. \"Edge-labeling graph neural network for few-shot learning.\" CVPR 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v119/goldblum20a.html\">Goldblum, Micah, et al. \"Unraveling meta-learning: Understanding feature representations for few-shot tasks.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://proceedings.mlr.press/v119/xu20i.html\">Xu, Jin, et al. \"Metafun: Meta-learning with iterative functional updates.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3327546.3327622\">Finn, Chelsea, Kelvin Xu, and Sergey Levine. \"Probabilistic model-agnostic meta-learning.\" ICML 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content/WACV2021/html/Fortin_Towards_Contextual_Learning_in_Few-Shot_Object_Classification_WACV_2021_paper.html\">Fortin, Mathieu Page, and Brahim Chaib-draa. \"Towards Contextual Learning in Few-Shot Object Classification.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v119/bronskill20a.html\">Bronskill, et al. \"TaskNorm: Rethinking Batch Normalization for Meta-Learning.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1803.02999\">Nichol, Alex, Joshua Achiam, and John Schulman. \"On first-order meta-learning algorithms.\" arXiv preprint arXiv:1803.02999 (2018).</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=umIdUL8rMH\">Oh, Jaehoon, et al. \"BOIL: Towards Representation Change for Few-shot Learning.\" ICLR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://dl.acm.org/doi/abs/10.5555/3326943.3327010\">Oreshkin, Boris N., et al. \"Tadam: Task dependent adaptive metric for improved few-shot learning.\" NIPS 2018.</a></li>\n</ul>\n<h3 id=\"incremental-learning-continual-learning\" style=\"position:relative;\"><a href=\"#incremental-learning-continual-learning\" aria-label=\"incremental learning continual learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Incremental Learning, Continual Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://ieeexplore.ieee.org/abstract/document/8107520\">Li, Zhizhong, and Derek Hoiem. \"Learning without forgetting.\" IEEE transactions on pattern analysis and machine intelligence 40.12 (2017): 2935-2947.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://www.sciencedirect.com/science/article/pii/S0893608019300231\">Parisi, German I., et al. \"Continual lifelong learning with neural networks: A review.\" Neural Networks 113 (2019): 54-71.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v119/yoon20b.html\">Yoon, Sung Whan, et al. \"XtarNet: Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning.\" ICML 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://papers.nips.cc/paper/2019/hash/e833e042f509c996b1b25324d56659fb-Abstract.html\">Ren, Mengye, et al. \"Incremental Few-Shot Learning with Attention Attractor Networks.\" NIPS 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content_CVPR_2020/html/Tao_Few-Shot_Class-Incremental_Learning_CVPR_2020_paper.html\">Tao, Xiaoyu, et al. \"Few-shot class-incremental learning.\" CVPR 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2007.04546\">Ren, Mengye, et al. \"Wandering within a world: Online contextualized few-shot learning.\" arXiv preprint arXiv:2007.04546, 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://ojs.aaai.org/index.php/AAAI/article/view/5942\">Luo, Yadan, et al. \"Learning from the Past: Continual Meta-Learning with Bayesian Graph Neural Networks.\" AAAI 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/Gidaris_Dynamic_Few-Shot_Visual_CVPR_2018_paper.html\">Gidaris, Spyros, and Nikos Komodakis. \"Dynamic few-shot visual learning without forgetting.\" CVPR 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2103.04059\">Cheraghian, Ali, et al. \"Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://ojs.aaai.org//index.php/AAAI/article/view/7079\">Liu, Bing. \"Learning on the job: Online lifelong and continual learning.\" AAAI 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1606.04671\">Rusu, Andrei A., et al. \"Progressive neural networks.\" arXiv preprint arXiv:1606.04671 (2016).</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=Sk7KsfW0-\">Yoon, Jaehong, et al. \"Lifelong Learning with Dynamically Expandable Networks.\" ICLR. 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2010.15277\">Masana, Marc, et al. \"Class-incremental learning: survey and performance evaluation.\" arXiv preprint arXiv:2010.15277 (2020).</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"file:///C:/Users/ECE/Desktop/16334-Article%20Text-19828-1-2-20210518.pdf\">Mazumder, Pratik, Pravendra Singh, and Piyush Rai. \"Few-Shot Lifelong Learning.\" AAAI 2021.</a></p>\n<ul>\n<li>CEC와 동일하게 data-init을 사용하여 base, novel classifier 생성</li>\n<li>CE loss를 사용하지 않고 triplet loss, minimize cosine similarity loss(for prototype), regularization loss를 사용</li>\n<li>전체 weight 중에서 크기가 작은 10%만 골라서, 이를 novel sample에 대해서 fine-tuning 진행</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Self-Promoted_Prototype_Refinement_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.html\">Zhu, Kai, et al. \"Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://www.pnas.org/content/114/13/3521.short\">Kirkpatrick, James, et al. \"Overcoming catastrophic forgetting in neural networks.\" PNAS 2017.</a></p>\n<ul>\n<li>Fisher Information Matrix를 사용하여, parameter space 상에서 특정 covariance를 제약으로 parameter 학습이 이루어지도록 하는 알고리즘 (mahalanobis distance와 동일한 formulation)</li>\n<li>논문 설명 블로그 <a href=\"https://yukyunglee.github.io/Fisher-Information-Matrix/\">링크1</a>, <a href=\"https://nzer0.github.io/Fisher-Info-and-NLL-Hessian.html\">링크2</a></li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/hash/357cfba15668cc2e1e73111e09d54383-Abstract.html\">Shi, Guangyuan, et al. \"Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima.\" NeurIPS 2021.</a></p>\n<ul>\n<li>Robust optimization과 관계가 깊은 논문. Figure 2만 봐도 논문이 말하고자 하는 내용은 파악 가능</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/ICCV2021/html/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.html\">Cha, Hyuntak, Jaeho Lee, and Jinwoo Shin. \"Co2l: Contrastive continual learning.\" ICCV 2021.</a></p>\n<ul>\n<li>Asymmetric SupCon loss로 novel learning하고, self-supervised instance-wise relation distill(IRD)로 preserve knowledge</li>\n<li>Asymmetric SupCon: current task와 memory buffer를 둘 다 사용하지만, anchor로는 current task만 사용. 이 경우에 그냥 SupCon보다 효과 좋음</li>\n<li>IRD: reference(previous) model output과 동일해지도록 현재 모델 regulate (대상은 2N개 전부)</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/pdf?id=gYgMSlZznS\">Hu, Dapeng, et al. \"How Well Does Self-Supervised Pre-Training Perform with Streaming ImageNet?.\" NeruIPS 2021.</a></p>\n<ul>\n<li>Self-supervised learning 방식으로 pre-training하면, streaming data에 대해서 joint training 만큼의 성능이 나온다는 것을 주장</li>\n<li>Pre-training은 MoCo-v2 protocol을 따르고, OpenSelfSup의 구현을 기반으로 하였음</li>\n<li>Streaming data의 distribution shift가 milld한 경우에는 joint training과 self-supervised pre-training의 성능이 거의 비슷하고, large distribution shift인 경우에는 MAS(memory aware synapse)와 data replay 방법을 사용하면 비슷함.</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=9Hrka5PA7LW\">Madaan, Divyam, et al. \"Rethinking the Representational Continuity: Towards Unsupervised Continual Learning.\" ICLR 2022.</a></p>\n<ul>\n<li>Label unannotated인 unsupervised continual learning(CURL)을 SimSiam과 Barlow Twining 알고리즘 사용하여 해결해보았더니 신기하게도 supervised continual learning보다 catastrophic forgetting에 robust 함</li>\n<li>Lifelong Unsupervised Mixup(LUMP)는 previous task(in memory buffer)와 current task 사이의 interpolate를 활용하는 방법이며, LUMP를 안 써도 잘하지만 LUMP 사용시 더 잘함</li>\n<li>UCL/SCL이 low layer에서는 similar하고 high layer에서는 dissimilar함. UCL의 loss landscape이 더 smooth 함.</li>\n<li>Test 단계에서 classifying은 KNN을 사용한다고 하는데, 어떻게 사용한건지 아직 제대로 살펴보진 않았음</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2112.04215.pdf\">Fini, Enrico, et al. \"Self-Supervised Models are Continual Learners.\" arXiv preprint arXiv:2112.04215, 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2202.08025\">Zhou, Minghao, et al. \"Diagnosing Batch Normalization in Class Incremental Learning.\" arXiv preprint arXiv:2202.08025, 2022.</a></p>\n<ul>\n<li>Training batch에 new class만 존재해야 better normalization &#x26; representation 학습 가능하지만, 이러면 모델이 BN discrepancy에 의해 편향됨. 이를 BN dilemma라고 함</li>\n<li>BN dilemma를 해소하기 위해서 BN trick(BNT) 방법을 제안</li>\n<li>EMA update는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>B</mi><mi>b</mi></msub></mrow><annotation encoding=\"application/x-tex\">B_b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> (balanced batch)로 하고, parameter update는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>B</mi><mi>t</mi></msub><mo separator=\"true\">,</mo><msub><mi>B</mi><mi mathvariant=\"script\">M</mi></msub></mrow><annotation encoding=\"application/x-tex\">B_t, B_\\mathcal{M}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathcal mtight\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>를 가지고 EMA update 없이 joint training</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/forum?id=vwLLQ-HwqhZ\">Pham, Quang, Chenghao Liu, and H. O. I. Steven. \"Continual normalization: Rethinking batch normalization for online continual learning.\" ICLR 2022.</a></p>\n<ul>\n<li>Previous task에 대한 inference 상황에서 current task에 biased된 moments를 사용하게 되는 현상을 cross-task normalization effect라고 함</li>\n<li>BN을 continual learning task에 단순히 사용하는 경우에 이런 cross-task normalization effect가 존재하기 때문에, GN과 같이 cross-task normalization effect 없는 method도 같이 사용하자는 것이 논문의 아이디어. 즉, mini-batch와 spatial normalization 사이에 balancing이 continual learning 에서의 normalization에 중요하다고 주장</li>\n<li>SwithNorm이나 TaskNorm과 같이 BN, LN, IN, GN 등의 blending weight 형태보다 GN -> BN (=CN)의 형태가 더 좋다고 주장</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2201.12559\">Cha, Sungmin, et al. \"Task-Balanced Batch Normalization for Exemplar-based Class-Incremental Learning.\" arXiv preprint arXiv:2201.12559, 2022.</a></p>\n<ul>\n<li>Exemplar-based CIL에 대해, task-balaneced <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> &#x26; <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\sigma^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span> 계산 방법과 affine transformation parameter를 덜 편향되게 하는 계산법을 제안함</li>\n<li>Task-balanced <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> &#x26; <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\sigma^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span> calculation: current biased 되지 않도록 reshape과 repeat 연산을 사용한 새로운 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> &#x26; <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\sigma^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span> 계산 방법 제안</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/forum?id=7pgFL2Dkyyy\">Skorokhodov, Ivan, and Mohamed Elhoseiny. \"Class Normalization for (Continual)? Generalized Zero-Shot Learning.\" ICRL 2021.</a></p>\n<ul>\n<li>ZSL에서 자주 사용되는 'normalize+scale'(NS) 방법과 'attributes normalization'(AN) 방법의 한계점을 언급하며 이를 개선한 CN 제안</li>\n<li>NS와 AN이 잘 되는 이유에 대한 informal한 분석/의견을 내놓으면서 이를 바탕으로 CN을 제안하는 과정이 매끄러움. 이 점 덕분에 accept이 되었다고 생각함</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/file/77ee3bc58ce560b86c2b59363281e914-Paper.pdf\">Zhu, Fei, et al. \"Class-Incremental Learning via Dual Augmentation.\" NeurIPS 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2203.06953.pdf\">Zhou, Da-Wei, et al. \"Forward compatible few-shot class-incremental learning.\" CVPR 2022.</a></li>\n</ul>\n<h3 id=\"domain-generalization\" style=\"position:relative;\"><a href=\"#domain-generalization\" aria-label=\"domain generalization permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Domain Generalization</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/hash/bcb41ccdc4363c6848a1d760f26c28a0-Abstract.html\">Cha, Junbum, et al. \"Swad: Domain generalization by seeking flat minima.\" NIPS 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Fan_Adversarially_Adaptive_Normalization_for_Single_Domain_Generalization_CVPR_2021_paper.html\">Fan, Xinjie, et al. \"Adversarially adaptive normalization for single domain generalization.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2012.04324.pdf\">Volpi, Riccardo, et al. \"Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning.\" CVPR 2021.</a></li>\n</ul>\n<h3 id=\"self-supervised-learning\" style=\"position:relative;\"><a href=\"#self-supervised-learning\" aria-label=\"self supervised learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Self-supervised Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2006.07733\">Grill, Jean-Bastien, et al. \"Bootstrap your own latent: A new approach to self-supervised learning.\" NIPS 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_CVPR_2019/html/Kolesnikov_Revisiting_Self-Supervised_Visual_Representation_Learning_CVPR_2019_paper.html\">Kolesnikov, Alexander, Xiaohua Zhai, and Lucas Beyer. \"Revisiting self-supervised visual representation learning.\" CVPR 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2102.06810\">Tian, Yuandong, Xinlei Chen, and Surya Ganguli. \"Understanding self-supervised Learning Dynamics without Contrastive Pairs.\" arXiv preprint arXiv:2102.06810, 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2103.05247?fbclid=IwAR3T_ZxXT0bmygQnpbWdPy_9_ilNR9nrCbALNgc6EffsXAevguFxQ_myPFE\">Kevin Lu, et al. \"Pretrained Transformers as Universal Computation Engines.\" arXiv preprint arXiv:2103.05247, 2021</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2103.01988\">Goyal, Priya, et al. \"Self-supervised Pretraining of Visual Features in the Wild.\" arXiv preprint arXiv:2103.01988, 2021.</a></li>\n</ul>\n<h3 id=\"semi-supervised-learning\" style=\"position:relative;\"><a href=\"#semi-supervised-learning\" aria-label=\"semi supervised learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Semi-supervised Learning</h3>\n<ul>\n<li>Generative model: Gaussian mixture, Deep generative models</li>\n<li>Graph based: Label propagation</li>\n<li>Self-training: Pseudo labelling, Co-training</li>\n<li>Consistency regularization: Pi-model, Mean teacher</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Pham_Meta_Pseudo_Labels_CVPR_2021_paper.html\">Pham, Hieu, et al. \"Meta pseudo labels.\" CVPR 2021.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/ijcai05.pdf\">Zhou, Zhi-Hua, and Ming Li. \"Semi-supervised regression with co-training.\" IJCAI 2005.</a></p>\n<ul>\n<li>두 개의 kNN regressor를 사용하여 co-training 진행</li>\n<li>Sufficient and redundant view를 위해서 두 regressor의 metric은 p=2 Minkowsky와 p=5 Minkowsky로 서로 다르게 설정함 </li>\n<li>Key mechanism은 regression에서 confidence를 만들어내는 작업이었고, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>가 추가됨에 따라서 MSE가 얼마나 개선되는지를 계산하여(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mo>△</mo><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\vartriangle_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69986em;vertical-align:-0.15em;\"></span><span class=\"mrel\"><span class=\"mrel amsrm\">△</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>) 이 값이 제일 커지는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>에 대해 confidence가 높다고 판단하여 해당 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>에 pseudo label을 부여</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://par.nsf.gov/servlets/purl/10080181\">Jean, Neal, Sang Michael Xie, and Stefano Ermon. \"Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance.\" NIPS 2018.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2019/hash/1cd138d0499a68f4bb72bee04bbec2d7-Abstract.html\">Berthelot, David, et al. \"Mixmatch: A holistic approach to semi-supervised learning.\" NeurIPS 2019.</a></p>\n<ol>\n<li>Unlabel data에 대해서 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개의 stochastic augmentation 수행 후 이를 모델에 입력</li>\n<li>모델이 뱉은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개의 probability 출력을 평균 낸 뒤에, temperature scailing을 통해 entropy minimization(sharpening) 수행. 그리고 이 값 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span></span></span></span>를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개의 unlabelled data가 공유</li>\n<li>배치 내에서 Labelled data는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span>개, Unlabelled data는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mo>∗</mo><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">B*K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개 존재하게 됨</li>\n<li>총 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mo>∗</mo><mo stretchy=\"false\">(</mo><mi>K</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">B*(K + 1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span> 개의 데이터를 섞은 뒤에 Labelled data <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span></span></span></span>개, Unlabelled data <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi><mo>∗</mo><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">B*K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span>개와 각각 Mixup</li>\n<li>이 때, mixup <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>λ</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>λ</mi><mo separator=\"true\">,</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\lambda&#x27; = \\max(\\lambda, 1-\\lambda)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.751892em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">λ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">λ</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mclose\">)</span></span></span></span>는 항상 0.5 이상이 나오도록 설정하여, labelled mixup data는 labelled data에 dominant 하고, unlabelled mixup data는 unlabelled data에 dominant 하도록 강제함</li>\n<li>Labelled mixup data로는 CE loss 계산, Unlabelled mixup data로는 Consistency loss 계산</li>\n</ol>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=HklkeR4KPB\">Berthelot, David, et al. \"ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring.\" ICLR 2020.</a></p>\n<ul>\n<li>Distribution Alignment: Unlabelled data의 예측 분포를 labelled data의 분포로 normalize. 즉, 기존 prediction <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span>에 unlabelled data 분포의 running average로 나누고 labelled data 분포의 running average로 곱해줌.</li>\n<li>Augmentation Anchoring</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf\">Sohn, Kihyuk, et al. \"Fixmatch: Simplifying semi-supervised learning with consistency and confidence.\" NeurIPS 2020.</a></p>\n<ul>\n<li>Labelled image: Weakly augmented image 사용해서 cross entropy</li>\n<li>Unlabelled image: Weakly augmented image에 대해서 threshold를 넘는 경우에 이 예측의 one-hot encoding을 strong augmented image의 pseudo label로써 사용. Threshold를 넘지 못하는 경우에는 loss에 포함시키지 않음</li>\n<li>원래는 temperatured scaling해서 pseudo label하였으나, temperature를 0으로 했을 때 잘 나왔다고 함 (이 경우 one-hot encoding과 동일)</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"open-set-recognition\" style=\"position:relative;\"><a href=\"#open-set-recognition\" aria-label=\"open set recognition permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Open-Set Recognition</h3>\n<ul>\n<li>Novelty Detection (ND) = One-Class Classification: Known class와 unknown class를 binary classification</li>\n<li>Open-Set Recognition (OSR): Known에 대한 closed-set classification과 unknown class detect를 동시에 수행</li>\n<li>Out-of-Distribution Detection (OOD): OSR과 유사하며, unknown class(outlier)가 더 넓은 도메인까지도 존재</li>\n<li>Anomaly Detection (AD): 학습 데이터가 모두 unlabeled. 즉, unsupervised learning 상황</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2105.14148\">Saito, Kuniaki, Donghyun Kim, and Kate Saenko. \"OpenMatch: Open-set Consistency Regularization for Semi-supervised Learning with Outliers.\" NeurIPS 2021.</a></p>\n<ul>\n<li>Open-set semi-supervised learning(OSSL) task를 풀기 위한 알고리즘</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/pdf?id=5hLP5JY9S2d\">Vaze, Sagar, et al. \"Open-Set Recognition: A Good Closed-Set Classifier is All You Need.\" ICLR 2022.</a></p>\n<ul>\n<li>Close-set classification을 잘하면 OSR도 잘한다는 것을 보인 논문 (이 두 performance 사이에 positive correlation이 존재한다)</li>\n<li>따라서 아주 기본적인 Maximum Softmax Probability (MSP) OSR 알고리즘만 사용해도, feature extractor 성능만 높으면 기존의 SOTA와 동일하거나 더 높은 성능을 얻을 수 있음</li>\n<li>해당 논문에서, softmax가 아닌 그 직전 값인 logit을 활용한 Maximum Logit Score (MLS) 방법과, Semantic Shift Benchmark (SSB) split도 추가적으로 제안하였음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2103.00953\">Chen, Guangyao, et al. \"Adversarial reciprocal points learning for open set recognition.\" TPAMI 2021.</a></p>\n<ul>\n<li>Porototype은 target class를 대표하는 벡터라면, reciprocal point는 non-target class를 대표하는 벡터임</li>\n<li>Unlabeled data가 존재할 수 있는 공간을 bounding 함</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"metric-learning\" style=\"position:relative;\"><a href=\"#metric-learning\" aria-label=\"metric learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Metric Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html\">Khosla, Prannay, et al. \"Supervised contrastive learning.\" NIPS 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2016/hash/6b180037abbebea991d8b1232f8a8ca9-Abstract.html\">Sohn, Kihyuk. \"Improved deep metric learning with multi-class n-pair loss objective.\" NIPS 2016.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/He_Triplet-Center_Loss_for_CVPR_2018_paper.html\">He, Xinwei, et al. \"Triplet-center loss for multi-view 3d object retrieval.\" CVPR 2018.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html\">Wu, Zhirong, et al. \"Unsupervised feature learning via non-parametric instance discrimination.\" CVPR 2018.</a></li>\n</ul>\n<h3 id=\"normalization-methods\" style=\"position:relative;\"><a href=\"#normalization-methods\" aria-label=\"normalization methods permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Normalization Methods</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://proceedings.neurips.cc/paper/2021/hash/2578eb9cdf020730f77793e8b58e165a-Abstract.html\">Lubana, Ekdeep S., Robert Dick, and Hidenori Tanaka. \"Beyond BatchNorm: towards a unified understanding of normalization in deep learning.\" NeurIPS 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2103.01499.pdf\">Ergen, Tolga, et al. \"Demystifying batch normalization in relu networks: Equivalent convex optimization models and implicit regularization.\" ICLR 2022.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2101.08692.pdf\">Brock, Andrew, Soham De, and Samuel L. Smith. \"Characterizing signal propagation to close the performance gap in unnormalized ResNets.\" ICLR 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"http://proceedings.mlr.press/v139/brock21a/brock21a.pdf\">Brock, Andy, et al. \"High-performance large-scale image recognition without normalization.\" ICML 2021.</a></li>\n</ul>\n<h3 id=\"novel-category-discovery\" style=\"position:relative;\"><a href=\"#novel-category-discovery\" aria-label=\"novel category discovery permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Novel Category Discovery</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/1908.09884.pdf\">Han, Kai, Andrea Vedaldi, and Andrew Zisserman. \"Learning to discover novel visual categories via deep transfer clustering.\" ICCV 2019.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openreview.net/forum?id=BJl2_nVFPB\">Han, Kai, et al. \"Automatically Discovering and Learning New Visual Categories with Ranking Statistics.\" ICLR 2020.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://ieeexplore.ieee.org/abstract/document/9464163/\">Han, Kai, et al. \"Autonovel: Automatically discovering and learning novel visual categories.\" TPAMI 2021.</a></p>\n<ol>\n<li>Self-supervised pre-training on labelled and unlabelled data using RotNet loss (training <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Φ</mi></mrow><annotation encoding=\"application/x-tex\">\\Phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Φ</span></span></span></span>)</li>\n<li>Supervised training on labelled data using CE loss (training the head <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>η</mi><mi>l</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\eta^l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.043548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span></span></span> and the last micro-block of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Φ</mi></mrow><annotation encoding=\"application/x-tex\">\\Phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Φ</span></span></span></span>)</li>\n<li>Training on pseudo-labelled data with ranking statisitics using BCE loss (training the head <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>η</mi><mi>u</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\eta^u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.858832em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span></span></span> and the last micro-block of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Φ</mi></mrow><annotation encoding=\"application/x-tex\">\\Phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\">Φ</span></span></span></span>)</li>\n<li>2번과 3번 joint training 수행. 하지만 3번이 매 epoch마다 다르게 pseudo-labelled 되어 학습의 불안정을 유발하므로, MSE를 consistency cost로써 추가 (자세한 식은 논문 참고)</li>\n</ol>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=MEpKGLsY8f\">Chi, Haoang, et al. \"Meta discovery: Learning to discover novel classes given very limited data.\" ICLR 2022.</a></p>\n<ul>\n<li>Learning to discover novel classes(L2DNC) task에 대해서 이전 가정이 이론적으로 잘못되었다는 것을 증명하고, 이론적으로 가능한 L2DNC 상황을 재정립함. 이와 더불어 더 실생활과 관련있는 few novel observation 상황을 가정하여, L2DNCL task를 정의함.</li>\n<li>재정립한 L2DNCL이 meta-learning의 가정과 유사하여 MAML, ProtoNet의 아이디어를 차용한 MM, MP를 제안함.</li>\n<li>Meta-learning에 L2DNCL를 접목할 수 있도록 Clustering-rule-aware Task Sampler(CATA)를 제안함.</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"http://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Neighborhood_Contrastive_Learning_for_Novel_Class_Discovery_CVPR_2021_paper.html\">Zhong, Zhun, et al. \"Neighborhood Contrastive Learning for Novel Class Discovery.\" CVPR 2021.</a></p>\n<ul>\n<li>Ranking Statistics(RS) 방법에 NCL, SCL, HNG 총 세 개의 방법을 더 추가한 논문. 다만 ranking statistics를 사용하여 pseudo-labelling 하지 않고, cosine similarity 기준으로 pseudo-labelling 수행</li>\n<li>Neighborhood Contrastive Learning(NCL): Unlabelled dataset을 위한 loss. Self-supervised contrastive loss와 더불어, similarity가 높은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 개의 feature를 positive라고 labelling해서 contrastive loss를 추가적으로 계산. <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"normal\">ℓ</mi><mrow><mi>n</mi><mi>c</mi><mi>l</mi></mrow></msub><mo>=</mo><mi>α</mi><msub><mi mathvariant=\"normal\">ℓ</mi><mrow><mo fence=\"true\">(</mo><msup><mi>z</mi><mi>u</mi></msup><mo separator=\"true\">,</mo><msup><mover accent=\"true\"><mi>z</mi><mo>^</mo></mover><mi>u</mi></msup><mo fence=\"true\">)</mo></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy=\"false\">)</mo><msub><mi mathvariant=\"normal\">ℓ</mi><mrow><mo fence=\"true\">(</mo><msup><mi>z</mi><mi>u</mi></msup><mo separator=\"true\">,</mo><msub><mi>ρ</mi><mi>k</mi></msub><mo fence=\"true\">)</mo></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\ell_{n c l}=\\alpha \\ell_{\\left(z^{u}, \\hat{z}^{u}\\right)}+(1-\\alpha) \\ell_{\\left(z^{u}, \\rho_{k}\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">ℓ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04964em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\"><span class=\"mord\">ℓ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord accent mtight\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span></span></span><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord mtight\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1052em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord\">ℓ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">u</span></span></span></span></span></span></span></span></span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">ρ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>Supervised Contrastive Learning(SCL): Labelled dataset을 위한 loss. 기존 supervised-contrastive loss와 동일</li>\n<li>Hard-Negative Generation(HNG): True negative(labelled dataset)와 easy negative(unlabelled dataset)를 interpolate 한 것 중에서 제일 유사도 높은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 개를 hard negative로 사용 </li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2201.02609.pdf\">Vaze, Sagar, et al. \"Generalized Category Discovery.\" CVPR 2022.</a></p>\n<ul>\n<li>Generalized Category Discovery라는 task를 처음으로 정의한 논문</li>\n<li>Main algorithm: ViT DINO pretraining, Supervised contrastive learning + Self-supervised contrastive learning, Semi-supervised k-means clustering(using k-means++)의 순서로 알고리즘 구성</li>\n<li>Class number estimation method: Brent's method 사용</li>\n<li>Strong baselines: RS와 UNO에서 labelled dataset와 unlabelled dataset에 대한 classification head가 두 개로 나뉘어 존재하던 것을 하나로 합침. Backbone은 저자들이 제안한 ViT구조를 그대로 사용하였는데, backbone을 finetuning하는 것은 오히려 성능이 좋지 않아서, backbone은 freeze하고 classification head만 tuning하였음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content_WACV_2020/html/Bhattacharjee_Multi-class_Novelty_Detection_Using_Mix-up_Technique_WACV_2020_paper.html\">Bhattacharjee, Supritam, Devraj Mandal, and Soma Biswas. \"Multi-class novelty detection using mix-up technique.\" WACV 2020.</a></p>\n<ul>\n<li>Test query를 novel class와 mixup하면 output prediction 값이 낮고, base class와 mixup하면 output prediction 값이 특정 하나의 class에 대해 높을 것이라 가정</li>\n<li>Open-set recognition task에서 자주 사용되는 K개의 sigmoid classifier 사용</li>\n<li>Class 마다 N개의 exemplar 이미지를 가지고, 해당 이미지와 test query의 mixed 샘플 output 확인. N개의 output을 평균내어 이를 membership score라는 이름으로 정의</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/abs/2207.10659\">Joseph, K. J., et al. \"Novel Class Discovery without Forgetting.\" ECCV 2022.</a></p>\n<ul>\n<li>NCD, GCD의 advanced setting인 NCD without Forgetting을 제안함</li>\n<li>GCD 세팅과, base data training 이후에 base data에 대한 접근이 제한된다는 점이 차이점 (GCD 보다 더 어려운 task)</li>\n<li>Pseudo-latent, Mutual information based regularizer, Known Class Indentifier라는 방법들을 통해 NCDwF를 해결하는데, 아직 자세히 이해하지는 못했음</li>\n</ul>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/2208.01898\">Fei, Yixin, et al. \"XCon: Learning with Experts for Fine-grained Category Discovery.\" arXiv preprint arXiv:2208.01898 (2022).</a></p>\n<ul>\n<li>Fine-grained dataset에 대해서, class-irrelevant cues(e.g. background, object pose) 위주로 clustering 되는 경향이 있음</li>\n<li>따라서 이를 해결하기 위해 dataset을 먼저 k-means clustering 하고(그러면 class-irrelevant cues 비슷한 것 끼리 얼추 모임), 이 data split에 대해 각각 contrastive learning을 수행하면 class-irrelevant cues로 인한 부정적인 영향을 줄일 수 있음</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"data-augmentation\" style=\"position:relative;\"><a href=\"#data-augmentation\" aria-label=\"data augmentation permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Augmentation</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openaccess.thecvf.com/content_ICCV_2019/html/Yun_CutMix_Regularization_Strategy_to_Train_Strong_Classifiers_With_Localizable_Features_ICCV_2019_paper.html\">Yun, Sangdoo, et al. \"Cutmix: Regularization strategy to train strong classifiers with localizable features.\" ICCV 2019.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" checked disabled> <a href=\"https://proceedings.mlr.press/v97/verma19a.html\">Verma, Vikas, et al. \"Manifold mixup: Better representations by interpolating hidden states.\" ICML 2019.</a></p>\n<ul>\n<li>기존 Input-spcae mixup과 달리 itermediate layer의 representation을 mixup하는 방법</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mrow><mo fence=\"true\">(</mo><msub><mover accent=\"true\"><mi>g</mi><mo>~</mo></mover><mi>k</mi></msub><mo separator=\"true\">,</mo><mover accent=\"true\"><mi>y</mi><mo>~</mo></mover><mo fence=\"true\">)</mo></mrow><mo>:</mo><mo>=</mo><mrow><mo fence=\"true\">(</mo><msub><mo><mi mathvariant=\"normal\">Mix</mi><mo>⁡</mo></mo><mi>λ</mi></msub><mrow><mo fence=\"true\">(</mo><msub><mi>g</mi><mi>k</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>g</mi><mi>k</mi></msub><mrow><mo fence=\"true\">(</mo><msup><mi>x</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow><mo separator=\"true\">,</mo><msub><mo><mi mathvariant=\"normal\">Mix</mi><mo>⁡</mo></mo><mi>λ</mi></msub><mrow><mo fence=\"true\">(</mo><mi>y</mi><mo separator=\"true\">,</mo><msup><mi>y</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\left(\\tilde{g}_{k}, \\tilde{y}\\right):=\\left(\\operatorname{Mix}_{\\lambda}\\left(g_{k}(x), g_{k}\\left(x^{\\prime}\\right)\\right), \\operatorname{Mix}_{\\lambda}\\left(y, y^{\\prime}\\right)\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.001892em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mop\"><span class=\"mop\"><span class=\"mord mathrm\">M</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">λ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop\"><span class=\"mord mathrm\">M</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">λ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></li>\n<li>SVD 했을 때 eigenvalue가 전체적으로 작아지는 효과를 가짐. 즉, principal components 수가 작아지는 효과 (flattening)</li>\n<li>Flattening을 통해 eigenvalue가 전체적으로 작아지니 volume이 작아지며, compression은 information theory 관점에서 이론적, 실험적으로 generalization과 연관이 있어 장점을 가짐</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/forum?id=g11CZSghXyY\">Wen, Yeming, et al. \"Combining Ensembles and Data Augmentation Can Harm Your Calibration.\" ICLR 2021.</a></li>\n</ul>\n<h3 id=\"natural-language-processing\" style=\"position:relative;\"><a href=\"#natural-language-processing\" aria-label=\"natural language processing permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Natural Language Processing</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=cu7IUiOhujH\">Gunel, Beliz, et al. \"Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning.\" ICLR 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://aclanthology.org/2020.acl-main.45.pdf\">Li, Xiaoya, et al. \"Dice Loss for Data-imbalanced NLP Tasks.\" ACL 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://aclanthology.org/C18-1182.pdf\">Yadav, Vikas, and Steven Bethard. \"A Survey on Recent Advances in Named Entity Recognition from Deep Learning models.\" COLING 2018.</a></li>\n</ul>\n<h3 id=\"reinforcement-learning\" style=\"position:relative;\"><a href=\"#reinforcement-learning\" aria-label=\"reinforcement learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reinforcement Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/1611.05763.pdf\">Wang, Jane X., et al. \"Learning to reinforcement learn.\" arXiv preprint arXiv:1611.05763, 2016</a></li>\n</ul>\n<h3 id=\"implicit-neural-representation\" style=\"position:relative;\"><a href=\"#implicit-neural-representation\" aria-label=\"implicit neural representation permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Implicit Neural Representation</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://link.springer.com/chapter/10.1007/978-3-030-58452-8_24\">Mildenhall, Ben, et al. \"Nerf: Representing scenes as neural radiance fields for view synthesis.\" ECCV 2020.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://openaccess.thecvf.com/content/CVPR2021/html/Martin-Brualla_NeRF_in_the_Wild_Neural_Radiance_Fields_for_Unconstrained_Photo_CVPR_2021_paper.html\">Martin-Brualla, Ricardo, et al. \"Nerf in the wild: Neural radiance fields for unconstrained photo collections.\" CVPR 2021.</a></li>\n</ul>\n<h3 id=\"neural-architecture-search\" style=\"position:relative;\"><a href=\"#neural-architecture-search\" aria-label=\"neural architecture search permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Neural Architecture Search</h3>\n<ul>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=S1eYHoC5FX\">Liu, Hanxiao, Karen Simonyan, and Yiming Yang. \"Darts: Differentiable architecture search.\" ICLR 2019.</a></p>\n<ul>\n<li>Neural Architecture Search (NAS) 연구에 대해, 기존에는 search space가 미분 불가능하다는 문제점 때문에 RL 기반으로만 연구가 진행었는데, DARTS는 search space를 미분 가능하게 정의하고 여기에 MAML의 최적화 방식과 동일한 bilevel optimization을 도입하여 gradient descent 기반의 NAS를 가능하도록 만들었음</li>\n<li>Differentiable archtecture search: 논문에서 정의한 bilevel optimization 식을 통한 가중치 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span> 최적화 수행</li>\n<li>Discretization step: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span>와 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> 기반으로 필요 없는 operation edge 제거</li>\n<li>Retraining for the top- <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span> strongest operations: 남은 operation edge에 대해 처음부터 다시 학습 수행</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"long-tailed-recognition\" style=\"position:relative;\"><a href=\"#long-tailed-recognition\" aria-label=\"long tailed recognition permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Long-Tailed Recognition</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://openreview.net/pdf?id=r1gRTCVFvB\">Kang, Bingyi, et al. \"Decoupling Representation and Classifier for Long-Tailed Recognition.\" ICLR 2020.</a></li>\n</ul>\n<h3 id=\"bayesian-deep-learning\" style=\"position:relative;\"><a href=\"#bayesian-deep-learning\" aria-label=\"bayesian deep learning permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bayesian Deep Learning</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://proceedings.mlr.press/v48/gal16.html\">Gal, Yarin, and Zoubin Ghahramani. \"Dropout as a bayesian approximation: Representing model uncertainty in deep learning.\" ICML 2016.</a> - <em>아직 읽지 않음..</em></li>\n</ul>\n<h3 id=\"technical-reports\" style=\"position:relative;\"><a href=\"#technical-reports\" aria-label=\"technical reports permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Technical Reports</h3>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2105.07576.pdf\">Wu, Yuxin, and Justin Johnson. \"Rethinking\" Batch\" in BatchNorm.\" arXiv preprint arXiv:2105.07576, 2021.</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/abs/1807.03341\">Lipton, Zachary C., and Jacob Steinhardt. \"Troubling trends in machine learning scholarship.\" arXiv preprint arXiv:1807.03341, 2018.</a></li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> <a href=\"https://arxiv.org/pdf/2204.03475.pdf\">Ridnik, Tal, et al. \"Solving ImageNet: a Unified Scheme for Training any Backbone to Top Results.\" arXiv preprint arXiv:2204.03475 , 2022.</a></p>\n<ul>\n<li>새로운 방법을 제안하는 논문은 아니고 technical report에 가까움</li>\n<li>ImageNet dataset에 대해서, 어떤 모델 구조더라도 하이퍼파라미터 튜닝 없이 동일하게 적용할 수 있는 USI(Unified Scheme for ImageNet)을 제안. Knowledge distillation과 몇 가지 modern tricks를 사용하였고, 모든 모델에 대해서 previous SOTA를 넘었음</li>\n<li>TResNet-L 구조의 teacher model과 더불어 논문에서 제안하는 하이퍼파라미터를 사용하면, CNN, Transformer, Mobile-oriented, MLP-only 형태의 student 모델에 대해서 모두 성능이 개선된다고 함</li>\n<li>일반적인 knowledge distillation 형태(vanilla KD)와 동일하게, true label y에 대해서는 cross entropy loss를 사용하고, teacher label에 대해서는 temperature를 사용하여 soft label을 만든 뒤에 student prediction과 KLD를 계산함</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" checked disabled> <a href=\"https://arxiv.org/pdf/2207.09238.pdf\">Phuong, Mary, and Marcus Hutter. \"Formal Algorithms for Transformers.\" <em>arXiv preprint arXiv:2207.09238</em> (2022).</a></li>\n</ul>","tableOfContents":"<ul>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#few-shot-learning-meta-learning\">Few-shot Learning, Meta Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#incremental-learning-continual-learning\">Incremental Learning, Continual Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#domain-generalization\">Domain Generalization</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#self-supervised-learning\">Self-supervised Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#semi-supervised-learning\">Semi-supervised Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#open-set-recognition\">Open-Set Recognition</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#metric-learning\">Metric Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#normalization-methods\">Normalization Methods</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#novel-category-discovery\">Novel Category Discovery</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#data-augmentation\">Data Augmentation</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#natural-language-processing\">Natural Language Processing</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#reinforcement-learning\">Reinforcement Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#implicit-neural-representation\">Implicit Neural Representation</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#neural-architecture-search\">Neural Architecture Search</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#long-tailed-recognition\">Long-Tailed Recognition</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#bayesian-deep-learning\">Bayesian Deep Learning</a></li>\n<li><a href=\"/MachineLearning/22-03-15-Deep%20Learning%20Paper%20List/#technical-reports\">Technical Reports</a></li>\n</ul>","frontmatter":{"path":"/deeplearning/22-03-15/","title":"Deep Learning Paper List","category":"Deep Learning","date":"2022-03-15"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}