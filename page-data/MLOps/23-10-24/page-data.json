{"componentChunkName":"component---src-templates-post-js","path":"/MLOps/23-10-24/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p>NVIDIA Triton Inference Server 사용을 위한 기본 개념들과 샘플 코드를 기록합니다. </p>\n</blockquote>\n<p>NVIDIA Triton은 NVIDIA가 직접 만든 모델 inference용 서버입니다. Triton 내부에서는 추론 최적화 및 GPU 활용률을 높일 수 있는 여러 기능들을 제공하고 있으며, 학습된 모델을 model repository에 저장하기만 하면 간단히 inference API를 만들 수도 있습니다.</p>\n<p>아직 작성중인 포스팅입니다.</p>\n<h3 id=\"model-repository\" style=\"position:relative;\"><a href=\"#model-repository\" aria-label=\"model repository permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model Repository</h3>\n<ul>\n<li>Model repository란</li>\n<li>Model repository 기본 구성 요소, directory 구조 살펴보기</li>\n</ul>\n<h3 id=\"model-configuration\" style=\"position:relative;\"><a href=\"#model-configuration\" aria-label=\"model configuration permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model Configuration</h3>\n<ul>\n<li>Model configuration 설정 방법</li>\n</ul>\n<h3 id=\"model-management\" style=\"position:relative;\"><a href=\"#model-management\" aria-label=\"model management permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model Management</h3>\n<h3 id=\"metrics\" style=\"position:relative;\"><a href=\"#metrics\" aria-label=\"metrics permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Metrics</h3>\n<h3 id=\"protocol\" style=\"position:relative;\"><a href=\"#protocol\" aria-label=\"protocol permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Protocol</h3>\n<ul>\n<li>HTTP/REST and gRPC</li>\n</ul>\n<h3 id=\"example-codes\" style=\"position:relative;\"><a href=\"#example-codes\" aria-label=\"example codes permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example Codes</h3>\n<p>아래의 순서대로 코드를 기록하기</p>\n<ol>\n<li>Model Training &#x26; JIT Export</li>\n<li>Create model repository</li>\n<li>Run Triton server</li>\n<li>Install Triton client</li>\n<li>Test inference (request)</li>\n</ol>\n<h3 id=\"references\" style=\"position:relative;\"><a href=\"#references\" aria-label=\"references permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>References</h3>\n<p>좋은 깃헙 예제들을 발견하여 아래에 공유합니다.</p>\n<ul>\n<li><a href=\"https://github.com/Curt-Park/triton-inference-server-practice\">https://github.com/Curt-Park/triton-inference-server-practice</a></li>\n<li><a href=\"https://github.com/fegler/triton_server_example\">https://github.com/fegler/triton_server_example</a></li>\n<li><a href=\"https://github.com/triton-inference-server/tutorials\">https://github.com/triton-inference-server/tutorials</a></li>\n</ul>\n<p>공부를 위한 문서들을 아래에 공유합니다.</p>\n<ul>\n<li><a href=\"https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/getting_started/quickstart.html\">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/getting_started/quickstart.html</a></li>\n<li><a href=\"https://developer.nvidia.com/blog/nvidia-serves-deep-learning-inference/\">https://developer.nvidia.com/blog/nvidia-serves-deep-learning-inference/</a></li>\n</ul>\n<p>더 쉬운 사용을 위한 wrapper 오픈소스도 존재하네요!</p>\n<ul>\n<li><a href=\"https://blog.rtzr.ai/tritony-tiny-configuration-for-triton-inference-server/\">https://blog.rtzr.ai/tritony-tiny-configuration-for-triton-inference-server/</a></li>\n</ul>","tableOfContents":"<ul>\n<li><a href=\"/MachineLearning/23-10-24-NVIDIA%20triton/#model-repository\">Model Repository</a></li>\n<li><a href=\"/MachineLearning/23-10-24-NVIDIA%20triton/#model-configuration\">Model Configuration</a></li>\n<li><a href=\"/MachineLearning/23-10-24-NVIDIA%20triton/#model-management\">Model Management</a></li>\n<li><a href=\"/MachineLearning/23-10-24-NVIDIA%20triton/#metrics\">Metrics</a></li>\n<li><a href=\"/MachineLearning/23-10-24-NVIDIA%20triton/#protocol\">Protocol</a></li>\n<li><a href=\"/MachineLearning/23-10-24-NVIDIA%20triton/#example-codes\">Example Codes</a></li>\n<li><a href=\"/MachineLearning/23-10-24-NVIDIA%20triton/#references\">References</a></li>\n</ul>","frontmatter":{"path":"/MLOps/23-10-24/","title":"NVIDIA Triton Inference Server","category":"MLOps","date":"2023-10-24"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}