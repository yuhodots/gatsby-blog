{"componentChunkName":"component---src-templates-post-js","path":"/MLOps/23-04-29/","result":{"data":{"markdownRemark":{"html":"<blockquote>\n<p>AI 모델 배포를 위한 라이브러리와 프레임워크들에 대해 간단히 기록합니다.</p>\n</blockquote>\n<h3 id=\"neural-network-exchange\" style=\"position:relative;\"><a href=\"#neural-network-exchange\" aria-label=\"neural network exchange permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Neural Network Exchange</h3>\n<h5 id=\"onnx-open-neural-network-exchange\" style=\"position:relative;\"><a href=\"#onnx-open-neural-network-exchange\" aria-label=\"onnx open neural network exchange permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ONNX: Open Neural Network Exchange</h5>\n<ul>\n<li>서로 다른 프레임워크로 만들어진 AI 모델을 서로 호환 가능하도록 Facebook과 Microsoft가 개발한 신경망 모델 포맷</li>\n<li>TensorFlow, PyTorch, SciKit-Learn, Keras, Chainer, MXNet, MATLAB, SparkML 등의 여러 프레임워크 모델을 표준 ONNX 형식으로 내보내거나 변환 가능</li>\n<li>Torch to ONNX 코드 출처: <a href=\"https://learn.microsoft.com/ko-kr/windows/ai/windows-ml/tutorials/pytorch-convert-model\">Microsoft - PyTorch 학습 모델을 ONNX로 변환</a></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>onnx \n\n<span class=\"token comment\">#Function to Convert to ONNX </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">Convert_ONNX</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> \n    <span class=\"token comment\"># set the model to inference mode </span>\n    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \n\n    <span class=\"token comment\"># Let's create a dummy input tensor  </span>\n    dummy_input <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> input_size<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>  \n\n    <span class=\"token comment\"># Export the model   </span>\n    torch<span class=\"token punctuation\">.</span>onnx<span class=\"token punctuation\">.</span>export<span class=\"token punctuation\">(</span>\n         model<span class=\"token punctuation\">,</span>    <span class=\"token comment\"># model being run </span>\n         dummy_input<span class=\"token punctuation\">,</span>    <span class=\"token comment\"># model input (or a tuple for multiple inputs) </span>\n         <span class=\"token string\">\"ImageClassifier.onnx\"</span><span class=\"token punctuation\">,</span>    <span class=\"token comment\"># where to save the model  </span>\n         export_params<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>    <span class=\"token comment\"># store the trained parameter weights inside the model file </span>\n         opset_version<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>    <span class=\"token comment\"># the ONNX version to export the model to </span>\n         do_constant_folding<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>    <span class=\"token comment\"># whether to execute constant folding for optimization </span>\n         input_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'modelInput'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>    <span class=\"token comment\"># the model's input names </span>\n         output_names <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'modelOutput'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>    <span class=\"token comment\"># the model's output names </span>\n         dynamic_axes<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">'modelInput'</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token number\">0</span> <span class=\"token punctuation\">:</span> <span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>    <span class=\"token comment\"># variable length axes </span>\n                       <span class=\"token string\">'modelOutput'</span> <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token number\">0</span> <span class=\"token punctuation\">:</span> <span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span> \n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span> \n    model <span class=\"token operator\">=</span> Network<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \n    path <span class=\"token operator\">=</span> <span class=\"token string\">\"myFirstModel.pth\"</span> \n    model<span class=\"token punctuation\">.</span>load_state_dict<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> \n    Convert_ONNX<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span> </code></pre></div>\n<h3 id=\"neural-network-optimization\" style=\"position:relative;\"><a href=\"#neural-network-optimization\" aria-label=\"neural network optimization permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Neural Network Optimization</h3>\n<h5 id=\"static-graph-vs-dynamic-graph\" style=\"position:relative;\"><a href=\"#static-graph-vs-dynamic-graph\" aria-label=\"static graph vs dynamic graph permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Static Graph vs. Dynamic Graph</h5>\n<ul>\n<li>정적 그래프(Static graph) 표현: 정적인 computational graph를 먼저 정의하고, 고정된 그래프에 데이터를 흘려주는 방식으로 동작. 동일한 그래프를 반복적으로 사용하므로 그래프에 대한 최적화가 쉽다는 장점</li>\n<li>동적 그래프(Dynamic graph) 표현: 데이터를 흘려보냄으로써 computational graph 정의됨. 즉, 매 iteration 마다 새로운 computational graph 구축. 조건문 반복문 등을 그대로 사용할 수 있으며 코드가 깔끔해지고 디버깅이 쉬워짐</li>\n</ul>\n<h5 id=\"tensorrt\" style=\"position:relative;\"><a href=\"#tensorrt\" aria-label=\"tensorrt permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TensorRT</h5>\n<ul>\n<li>학습된 Deep Learning 모델을 최적화하여 NVIDIA GPU 상에서의 Inference 속도를 수배에서 수십배까지 개선해주는 모델 최적화 엔진</li>\n<li>NVIDIA platform에서 최적의 inference 성능을 낼 수 있도록 network compression, network optimization 그리고 GPU 최적화 기술들을 대상 딥러닝 모델에 자동으로 적용</li>\n<li>FP32에서 precision을 낮추는 <em>Quantization &#x26; Precision Calibration</em>, Layer Fusion 방식과 Tensor Fusion 방식 기반의 <em>Graph Optimization</em>, 그리고 <em>Kernel Auto-tuning, Dynamic Tensor Memory &#x26; Multi-stream execution</em> 등의 기술 적용됨</li>\n<li>ONNX와 TensorRT 함께 사용시에, 여러 서로 다른 프레임워크로 만들어진 모델을 호환 가능하게 만들면서도 빠른 추론이 가능. 실제로 TensorFlow나 Pytorch로 모델 개발하고, ONNX로 포멧 바꾸고, TensorRT로 컴파일하는 형태 일반적임</li>\n</ul>\n<h5 id=\"torchscript\" style=\"position:relative;\"><a href=\"#torchscript\" aria-label=\"torchscript permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TorchScript</h5>\n<ul>\n<li>TorchScript는 C++와 같은 고성능 환경에서 실행될 수 있는 PyTorch 모델의 중간 표현(IR)임 (i.e., PyTorch의 그래프 표현)</li>\n<li>Eager mode: normal python runtime mode로 학습 단계에서 사용</li>\n<li>Script mode: 빠른 추론 및 배포를 위해 변환한 mode. 런타임 과정에서 python interpreter로 실행되지 않아 최적화 가능</li>\n<li>PyTorch JIT: PyTorch 프로그램에 최적화된 컴파일러</li>\n<li>TorchScript 변환 방식 1. JIT Trace: (dummy) input을 모델에 흘려보내 모델 구조를 파악하는 방식</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">dummy_input <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>rand<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">)</span>\nscript_module <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>jit<span class=\"token punctuation\">.</span>trace<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> dummy_input<span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>TorchScript 변환 방식 2. JIT Script: 코드를 직접 TorchScript로 변환하는 방식</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">instance <span class=\"token operator\">=</span> MyModule<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">)</span>\nscript_module <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>jit<span class=\"token punctuation\">.</span>script<span class=\"token punctuation\">(</span>instance<span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"gpu-programming\" style=\"position:relative;\"><a href=\"#gpu-programming\" aria-label=\"gpu programming permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GPU Programming</h3>\n<h5 id=\"triton\" style=\"position:relative;\"><a href=\"#triton\" aria-label=\"triton permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Triton</h5>\n<ul>\n<li>TensorRT, TorchScript만 사용하면 되는가?: Static graph만으로 모든 걸 알 순 없음</li>\n<li>Triton: OpenAI가 만든 언어 및 컴파일러. I/O 최적화된 CUDA 코드를 최적화</li>\n<li>관련 내용은 <a href=\"https://www.youtube.com/watch?v=Se62pRpk9A0\">김태훈 님의 2023 Deview 발표 영상</a>에서 확인. 더 공부하여 내용 추가하기</li>\n</ul>\n<h3 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor-header before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h3>\n<ul>\n<li><a href=\"https://developer.nvidia.com/ko-kr/blog/nvidia-tensorrt-inference-%EC%B5%9C%EC%A0%81%ED%99%94-%EB%B0%8F-%EA%B0%80%EC%86%8D%ED%99%94%EB%A5%BC-%EC%9C%84%ED%95%9C-nvidia%EC%9D%98-toolkit/\">NVIDIA TensorRT – Inference 최적화 및 가속화를 위한 NVIDIA의 Toolkit</a></li>\n<li><a href=\"https://towardsdatascience.com/pytorch-jit-and-torchscript-c2a77bac0fff\">PyTorch JIT and TorchScript</a></li>\n<li><a href=\"https://tutorials.pytorch.kr/beginner/Intro_to_TorchScript_tutorial.html\">파이토치 한국 사용자 모임 - TORCHSCRIPT 소개</a></li>\n</ul>","tableOfContents":"<ul>\n<li>\n<p><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#neural-network-exchange\">Neural Network Exchange</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#onnx-open-neural-network-exchange\">ONNX: Open Neural Network Exchange</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#neural-network-optimization\">Neural Network Optimization</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#static-graph-vs-dynamic-graph\">Static Graph vs. Dynamic Graph</a></li>\n<li><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#tensorrt\">TensorRT</a></li>\n<li><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#torchscript\">TorchScript</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#gpu-programming\">GPU Programming</a></p>\n<ul>\n<li>\n<ul>\n<li><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#triton\">Triton</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"/MachineLearning/23-04-29-Model%20Optimization%20for%20Deployment%20and%20Inference/#reference\">Reference</a></li>\n</ul>","frontmatter":{"path":"/MLOps/23-04-29/","title":"Deep Learning Model Serving","category":"MLOps","date":"2023-04-29"}}},"pageContext":{}},"staticQueryHashes":["2390655019","256249292","63159454"]}